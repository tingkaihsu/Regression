{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##and Professor suggests that we could use mass, classifacation for later application\n",
    "def SetAKArr(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    n_particles_ls = []\n",
    "    px_ls = []\n",
    "    py_ls = []\n",
    "    pz_ls = []\n",
    "    energy_ls = []\n",
    "    mass_ls = []\n",
    "    charge_ls = []\n",
    "    _label1 = []\n",
    "    _label2 = []\n",
    "    _label3 = []\n",
    "    _label4 = []\n",
    "    _label5 = []\n",
    "    \n",
    "    n = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('E'):\n",
    "            if not n == 0:\n",
    "                n_particles_ls.append(n)\n",
    "                n = 0\n",
    "            exp_inf = line.split()\n",
    "#             _label1.append(int(exp_inf[1]))\n",
    "#             _label2.append(1-int(exp_inf[1]))\n",
    "#             _label1.append(1)\n",
    "#             _label2.append(0)\n",
    "            _label1.append(float(exp_inf[1]))\n",
    "            _label2.append(float(exp_inf[2]))\n",
    "            _label3.append(float(exp_inf[3]))\n",
    "            _label4.append(float(exp_inf[4]))\n",
    "            _label5.append(float(exp_inf[5]))\n",
    "        else:\n",
    "            par = line.split()\n",
    "            ##particle +1\n",
    "            n = n + 1\n",
    "            px_ls.append(float(par[2]))\n",
    "            py_ls.append(float(par[3]))\n",
    "            pz_ls.append(float(par[4]))\n",
    "            energy_ls.append(float(par[5]))\n",
    "            mass_ls.append(float(par[6]))\n",
    "            charge_ls.append(int(par[0]))\n",
    "#             px_ls.append(6)\n",
    "#             py_ls.append(2)\n",
    "#             pz_ls.append(3)\n",
    "#             energy_ls.append(4)\n",
    "#             mass_ls.append(5)\n",
    "    if not n == 0:\n",
    "        n_particles_ls.append(n)\n",
    "    px_arr = np.array(px_ls)\n",
    "    py_arr = np.array(py_ls)\n",
    "    pz_arr = np.array(pz_ls)\n",
    "    energy_arr = np.array(energy_ls)\n",
    "    mass_arr = np.array(mass_ls)\n",
    "    charge_arr = np.array(charge_ls)\n",
    "    n_particles = np.array(n_particles_ls)\n",
    "\n",
    "#     print(n_particles)\n",
    "    px = ak.JaggedArray.fromcounts(n_particles, px_arr)\n",
    "    py = ak.JaggedArray.fromcounts(n_particles, py_arr)\n",
    "    pz = ak.JaggedArray.fromcounts(n_particles, pz_arr)\n",
    "    energy = ak.JaggedArray.fromcounts(n_particles, energy_arr)\n",
    "    mass = ak.JaggedArray.fromcounts(n_particles, mass_arr)\n",
    "    charge = ak.JaggedArray.fromcounts(n_particles, charge_arr)\n",
    "    p4 = uproot_methods.TLorentzVectorArray.from_cartesian(px, py, pz, energy)\n",
    "    ##Create an Order Dic\n",
    "    from collections import OrderedDict\n",
    "    v = OrderedDict()\n",
    "    v['part_px'] = px\n",
    "#     print(px)\n",
    "    v['part_py'] = py\n",
    "    v['part_pz'] = pz\n",
    "    v['part_energy'] = energy\n",
    "    v['part_mass'] = mass\n",
    "    v['charge'] = charge\n",
    "#     v['part_e_log'] = np.log(energy)\n",
    "#     v['part_px_log'] = np.log(px)\n",
    "#     v['part_py_log'] = np.log(py)\n",
    "#     v['part_pz_log'] = np.log(pz)\n",
    "#     v['part_m_log'] = np.log(mass)\n",
    "    v['label'] = np.stack((_label1, _label2, _label3, _label4, _label5), axis = -1)\n",
    "    v['label'] = np.stack(_label5, axis = -1)\n",
    "#     print(v['label'])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, filepath, feature_dict = {}, label = 'label', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict) == 0:\n",
    "            feature_dict['points'] = ['part_px','part_py','part_pz']\n",
    "            feature_dict['features'] = ['part_energy', 'part_mass', 'charge', 'part_px', 'part_py', 'part_pz']\n",
    "            feature_dict['mask'] = ['part_energy']\n",
    "        ##currently we use 'E' for experiments\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "        \n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "#         counts = None\n",
    "        a = SetAKArr(self.filepath)\n",
    "        self._label = a[self.label]\n",
    "        for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                    ##check the dimesion of a[col], and it should be array.\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:19:46,234] INFO: Start loading file train.txt\n",
      "[2024-04-02 15:19:47,904] INFO: Finished loading file train.txt\n",
      "[2024-04-02 15:19:47,906] INFO: Start loading file val.txt\n",
      "[2024-04-02 15:19:48,124] INFO: Finished loading file val.txt\n",
      "[2024-04-02 15:19:48,125] INFO: Start loading file test.txt\n",
      "[2024-04-02 15:19:48,325] INFO: Finished loading file test.txt\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset('train.txt', data_format='channel_last')\n",
    "val_dataset = Dataset('val.txt', data_format='channel_last')\n",
    "test_dataset = Dataset('test.txt', data_format = 'channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "##this shows the number of classes for classification\n",
    "try:\n",
    "    num_classes = train_dataset.y.shape[1]\n",
    "except:\n",
    "    num_classes = 1\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 10:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 20:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:20:02,997] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_NotEqual (TensorFlo [(None, 100, 1)]     0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, 100, 1)]     0           tf_op_layer_NotEqual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_1 (TensorFlowO [(None, 100, 1)]     0           tf_op_layer_Equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 100, 1)]     0           tf_op_layer_Cast_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add (TensorFlowOpLa [(None, 100, 3)]     0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose (TensorFl [(None, 3, 100)]     0           tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 100, 1, 6)]  0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2 (Tens [(None, 100, 100)]   0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(None, 100, 3)]     0           tf_op_layer_Add[0][0]            \n",
      "                                                                 tf_op_layer_Add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 6)    24          tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 100, 1)]     0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 100, 6)]     0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_Sum[0][0]            \n",
      "                                                                 tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_1 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_Transpose_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2 (TensorFlowO [(None, 100, 8), (No 0           tf_op_layer_Neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 1, 1, 1)]    0           tf_op_layer_Range[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 100, 7)]     0           tf_op_layer_TopKV2[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, 100, 7, 1)]  0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 100, 7, 2)]  0           tf_op_layer_Tile[0][0]           \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_1 (TensorFlowO [(None, 100, 7, 6)]  0           tf_op_layer_ExpandDims_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd (TensorFlo [(None, 100, 7, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 100, 7, 6)]  0           tf_op_layer_GatherNd[0][0]       \n",
      "                                                                 tf_op_layer_Tile_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 100, 7, 12)] 0           tf_op_layer_Tile_1[0][0]         \n",
      "                                                                 tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   384         tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 100, 1, 6)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   192         tf_op_layer_ExpandDims_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None, 100, 32)]    0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 100, 32)]    0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 100, 32)]    0           tf_op_layer_Squeeze_1[0][0]      \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_1 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_2 (Tensor [(None, 32, 100)]    0           tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_1 (Te [(None, 100, 100)]   0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Add_1[0][0]          \n",
      "                                                                 tf_op_layer_Add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_BatchMatMulV2_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_Mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_2[0][0]          \n",
      "                                                                 tf_op_layer_Mul_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_3 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(3,)]               0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 100, 100)]   0           tf_op_layer_Sub_2[0][0]          \n",
      "                                                                 tf_op_layer_Transpose_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_1 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Range_1 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_1 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_Range_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_1[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_2 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_5 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_2[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_3 (TensorFlowO [(None, 100, 7, 32)] 0           tf_op_layer_ExpandDims_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_1 (TensorF [(None, 100, 7, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf_op_layer_concat_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_3 (TensorFlowOp [(None, 100, 7, 32)] 0           tf_op_layer_GatherNd_1[0][0]     \n",
      "                                                                 tf_op_layer_Tile_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 100, 7, 64)] 0           tf_op_layer_Tile_3[0][0]         \n",
      "                                                                 tf_op_layer_Sub_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_6 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf_op_layer_ExpandDims_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_2 (TensorFl [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 100, 64)]    0           tf_op_layer_Squeeze_2[0][0]      \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_7 (TensorFlowOp [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_2 (TensorFlowO [(None, 64)]         0           tf_op_layer_Mul_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        tf_op_layer_Mean_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,969\n",
      "Trainable params: 26,189\n",
      "Non-trainable params: 780\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "#               metrics=['accuracy'])\n",
    "# model.compile(loss='log_cosh',\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "#               metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class LossLogger(Callback):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "#         self.lb = lb\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with open(self.filename, 'a') as f:\n",
    "#             print(\"Epoch \", epoch + 1,\": loss = \", logs[\"val_loss\"], \"\\n\", file = f)\n",
    "#             if (epoch+1)%5==0 or epoch==0:\n",
    "            print('V ', logs['val_loss'], file = f)\n",
    "            print('L', logs['loss'], file = f)\n",
    "#             print()\n",
    "#             f.write()\n",
    "# loss_logger = LossLogger('MSE_vac_loss.txt')\n",
    "loss_logger = LossLogger('MSE_loss.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = '%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='loss.txt',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "# I change the monitor from val_acc to val_loss\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "#                              monitor='val_loss',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler, loss_logger]\n",
    "# callbacks = [lr_schedule]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:20:20,433] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 8.5888 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:20:58,443] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 36s 953ms/step - loss: 8.5888 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 20.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:20:58,446] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:21:33,827] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 34s 908ms/step - loss: 0.2522 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 19.3832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:21:33,829] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:22:11,496] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 966ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 18.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:22:11,498] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:22:48,578] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 36s 951ms/step - loss: 0.1120 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 16.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:22:48,580] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:23:25,556] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 36s 948ms/step - loss: 0.1006 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 13.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:23:25,558] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:24:05,289] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 39s 1s/step - loss: 0.0926 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 11.3334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:24:05,292] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:24:43,896] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 988ms/step - loss: 0.0876 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 8.6911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:24:43,898] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:25:22,301] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 985ms/step - loss: 0.0847 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 6.2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:25:22,303] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:26:00,635] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 983ms/step - loss: 0.0807 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 4.2740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:26:00,637] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:26:39,900] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0788 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 2.7134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:26:39,902] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:27:18,896] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0769 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.7416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:27:18,899] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:27:58,540] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 39s 1s/step - loss: 0.0757 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 1.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:27:58,542] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:28:37,229] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 991ms/step - loss: 0.0746 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:28:37,231] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:29:16,119] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 997ms/step - loss: 0.0743 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.3188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:29:16,122] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:29:54,071] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 973ms/step - loss: 0.0742 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:29:54,073] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:30:32,044] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 974ms/step - loss: 0.0749 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:30:32,046] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:31:09,967] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 972ms/step - loss: 0.0738 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:31:09,969] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:31:48,075] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 978ms/step - loss: 0.0741 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:31:48,077] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:32:27,666] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 39s 1s/step - loss: 0.0725 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:32:27,668] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:33:07,422] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 39s 1s/step - loss: 0.0732 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:33:07,425] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:33:46,655] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0733 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:33:46,657] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:34:25,202] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 989ms/step - loss: 0.0728 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:34:25,204] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:35:04,467] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0721 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:35:04,470] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:35:43,930] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0716 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:35:43,933] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:36:23,081] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0720 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:36:23,084] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:37:01,678] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 988ms/step - loss: 0.0714 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:37:01,680] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:37:40,313] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 991ms/step - loss: 0.0712 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:37:40,315] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:38:19,306] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0714 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:38:19,309] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:38:57,822] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 988ms/step - loss: 0.0709 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:38:57,824] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:39:36,499] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 991ms/step - loss: 0.0702 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:39:36,502] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:40:15,027] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 987ms/step - loss: 0.0719 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:40:15,029] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:40:53,645] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 990ms/step - loss: 0.0704 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:40:53,647] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:41:32,052] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 985ms/step - loss: 0.0700 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:41:32,054] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:42:11,088] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0696 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:42:11,090] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:42:49,344] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 981ms/step - loss: 0.0701 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:42:49,346] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:43:27,664] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 983ms/step - loss: 0.0689 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:43:27,667] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:44:06,289] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 991ms/step - loss: 0.0691 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:44:06,291] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:44:44,762] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 37s 986ms/step - loss: 0.0683 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:44:44,765] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:45:23,439] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 991ms/step - loss: 0.0683 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:45:23,441] INFO: Learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 15:46:02,774] WARNING: Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/38 [==============================] - 38s 1s/step - loss: 0.0688 - accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7a3f3b51d7f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=5,\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MSE_pre_40epoches.txt', 'w') as file:\n",
    "    \n",
    "    predictions = model.predict(test_dataset.X)\n",
    "    for prediction in predictions:\n",
    "        print(prediction, file = file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "def PlotPrediction(filepath, fig, tag):\n",
    "    #open files\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    output = open('40predictions.txt', 'w')\n",
    "        \n",
    "    ##this piece of code would load the \n",
    "    ##real particle infor in order to be compared with the predictions\n",
    "    true_vals = []\n",
    "    true_val = []\n",
    "    masses = []\n",
    "    for line in lines:\n",
    "        if line.startswith('E'):\n",
    "            if not true_val:\n",
    "                true_vals.append(true_val)\n",
    "            true_val = []\n",
    "            info = line.split()\n",
    "            px = float(info[1])\n",
    "            py = float(info[2])\n",
    "            pz = float(info[3])\n",
    "            engy = float(info[4])\n",
    "            mass = float(info[5])\n",
    "            true_val.append(px)\n",
    "            true_val.append(py)\n",
    "            true_val.append(pz)\n",
    "            true_val.append(engy)\n",
    "            true_val.append(mass)\n",
    "            if tag == 'Px':\n",
    "                masses.append(px)\n",
    "            elif tag == 'Py':\n",
    "                masses.append(py)\n",
    "            elif tag == 'Pz':\n",
    "                masses.append(pz)\n",
    "            elif tag == 'Engy':\n",
    "                masses.append(engy)\n",
    "            else:\n",
    "                masses.append(mass)\n",
    "    \n",
    "    predictions = model.predict(test_dataset.X)mes\n",
    "    \n",
    "    x = []\n",
    "    for i in range(0, predictions.size):\n",
    "        x.append(i)\n",
    "        i += 1\n",
    "    quans = []\n",
    "##this is for multiple output variables\n",
    "#     if tag == 'Px':\n",
    "#         idx = 0\n",
    "#     elif tag == 'Py':\n",
    "#         idx = 1\n",
    "#     elif tag == 'Pz':\n",
    "#         idx = 2\n",
    "#     elif tag == 'Engy':\n",
    "#         idx = 3\n",
    "#     else:\n",
    "#         idx = 4\n",
    "    idx = 0\n",
    "    for prediction in predictions:\n",
    "        #this would grab the desired information\n",
    "        quan = prediction[idx]\n",
    "        quans.append(quan)\n",
    "        ##this would output the prediction into text\n",
    "        for energy_momentum in prediction:\n",
    "            print(energy_momentum, end='', file=output)\n",
    "        print('', file=output)\n",
    "        \n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.set_title(\"Mass Prediction\")\n",
    "#     plt.xlabel(\"Number of Prediction\")\n",
    "#     plt.ylabel(\"Mass\")\n",
    "#     ax.scatter(x, masses, linewidth=2.0, color = 'blue')\n",
    "\n",
    "    plt.hist(quans, 40, label='prediction', density=False, color = 'g', alpha = 0.75)\n",
    "    plt.hist(masses, 40, label='prediction', density=False, histtype = 'step', cumulative=False, color = 'b', alpha = 0.75)\n",
    "    plt.xlabel(tag+'(GeV)')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(tag+'Prediction of MSE')\n",
    "    plt.grid(True)\n",
    "\n",
    "#     plt.legend(\n",
    "#     loc='best',\n",
    "#     labels = ['log_cosh', 'mse'])\n",
    "#     plt.show()\n",
    "    plt.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-442f87a7f528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPlotPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predictions/Mass_PreFalse.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Mass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-a707cf21f13c>\u001b[0m in \u001b[0;36mPlotPrediction\u001b[0;34m(filepath, fig, tag)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mmasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# PlotPrediction('test.txt','predictions/Mass_PreFalse.png','Mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotWithoutModel(filepath, fig, tag):\n",
    "    TrueMass = 5.27933\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    masses = []\n",
    "    for line in lines:\n",
    "        masses.append(float(line))\n",
    "    plt.hist(masses, 40, label='prediction', density=False, color = 'g', alpha = 0.75)\n",
    "    # Mark True mass\n",
    "    plt.axvline(TrueMass, color='red', linestyle='--', label='Marked Point')\n",
    "    \n",
    "    plt.xlabel(tag+'(GeV)')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(tag+'Prediction of MSE')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw0AAAIqCAYAAABmP6baAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XmcXWV9+PHPV5YgSdiCCqgsVQKooALWAioTat2KoCwttGKiIrhQBcH2V0FNrFLbQlktCloS1AKKIg0urcIERKgKWCkVCFtANmtYQsIStu/vj3Pu5DLMnFnumblzZj7v1+u+7rnnPM9zvvceJtzvfZ7nPJGZSJIkSdJgntftACRJkiRNbCYNkiRJkiqZNEiSJEmqZNIgSZIkqZJJgyRJkqRKJg2SJEmSKpk0SJIkSapk0iBJkiSpkkmDJEmSpEomDZIkSZIqmTRIkiRJqmTSIEmSJKmSSYMkSZKkSiYNkqRaRMS8iMiIWDLAsWXlsZ5xjGd+ec6F43XOboqIdSPi0xFxQ0Q8Xr737HZckiYHkwZJE1ZELGx98YmIJyPihUOU37etfEbEvHEKtRYRsXW/+FuPJyLinoi4OCIO6HacE0GZEMyPiI26HcsE8iXgc8D2wFPA78rHkNoSrNZj5yHKv7pf+fmDlFs/Ij4WEb0R8fvyv+XlEXF9RFwYEUdGxCsHqDdvgL+DwR7fG857lNSZtbsdgCQN09rAXwAnV5SZO06xjIcHgSfK7RnA5sCfAn8aEd8CDs7MZ7oV3CjcCjwOPFpTe58tnxcCDw1SZjlwE3BvTeecsCJiQ2Be+XL/zPxuh02+F7i24viQf2sR8XLgR8DL2nY/AqwLvLJ8vAv4NfCaiqaGSnweHCoWSZ2zp0FSE9xZPr93sAIRsQnFl+pVwAPjEdQY2y8zNysfM4BtgX8vj/0Z8LHuhTZymfnHmbl9Zv5iHM95ennOvx2vc3bRdhSJ9f0dJgx3Ac8AB0fEgD8sRsRaFAl8Ar8dpMzawPcoEob7gA8Dm2TmjMzcAJgF7AOcAzxWFVDb38Fgj/eN7q1KGgmTBklNcBXFL9WvHWgoQ+kgil8wv8MQX0KaKDNvAQ4Abix3fbiL4WjieX75vKrDdu4GlgAvBN46SJm3Ai8CLmdNQt/fmyl6EgDemZlfzsy+HoHMfCAzF2fmXGBOhzFLGgcmDZKa4uvl82C9Da3951Q1EhGzI+IzEXFpRNxeThh9KCL+KyKOjojnV9R9dUScU07qXR0RKyPitoj4UTk2e/1+5deNiI9HxJXlOZ6MiN9FxK8j4ksRsduw3z2QmU9SJEUAsyNiRtu5+iYaR8SLI+JfythWR8R/D/Be3hAR50XEXWWZ+yPiJxFxcERExWewRUScGRF3l5/dbRHxz0PNLRhqInRErBMRh0XEJeXY99URcUdE/Ge5f3pZbmE8e3Lv7f3Gty9sa7NyInREPC8iPhARl0XEA+X7ub18fy8fpE5P2eay8vUeUcw1WR4Rj5XX9oiqz3AoEfGyiPhK+dk+HhEPRsTlEXFo+St/e9l55eexpNy1Vb/PY94oQmj9DXXyt7Zj+fy7zLy66mSZ+fgIYpPUJc5pkNQUXwfmA38ZEX/bPp4/ImYDr6cYKrFkiHb+Ddil3H6cYoz1xmX91wMHRcRembmyvVJEvINiuMU65a7VFMM4tikfb6UYv31jWX5t4D+BPcvyCaygGJbxQmCncvuqYb7/lrvbtjfgub8szwa+DWxKMX/gyf4NRMQ/AH/dtuthis/gj8vHPhHxl/3nTETEDsBlwAvKXY8AmwFHAe8Ezhjhe2m1+2LgYtaMa3+GYp7CZsCWwJ8ASymu7QqKMe4vKssuB55ua27FMM+5PnAh8JZy15MUn9fWwAeBQyLioMy8qKKNecBXKX6AexhYj+K6nga8HDhyOLH0a3Nviuu3XrlrBTAdeGP5+POIeFdmPlIef4zi81iX4ho+A/y+rcnR9Lp9B/gXiv8ONszMvs80IjYA9i3bvQB4/xBtbRIR65kYSM1nT4OkRsjM24CfAS+m+GLbrvXL5zeHMTn458ChwNaZ+fzMnEUxtGMfii+muwJfHKDe6RQJw8XAdpm5XmZuCGwIvAk4iyIJafkLioThUeAQYP3M3BiYBmwFHEExAXSktmzbHmgC8IkUE3/3yMzp5XyIvjsuRcTHKRKG3wGHARuV72M6xRCv+8rnv2lvNCLWofiS+ALgNmDPsu0ZFJ/dhsBnRvpmImIasJgiYVhOMcF2g/K6rE+R4J1M+eU3Mz+emZu1NfG6fuPbPz7MU/8zRcKwGvgQMDMzN6KYG7CE4kv7v5UJ6UBeAHyFIlHavKy7MUXCAPCxGHwo3YAi4mXAeeW5LwO2L9udCRxexvpm4JRWncw8v/w89it3/bbf53H+SGIo21xFkVCtRzF/pt2flfsvysyHK5pp9S6sA3w5ImaONA5JE0xm+vDhw8eEfFDcGSeB88rXh5Wvz2krE8Cycv8O5b67ytfzRni+bSh+cX6E4kt+a/8Ly/YSeNEw2/qXsvwZIzj/1m3n6Rng+PrAHeXx/+l3rPUZPDhYjMBGwEqKL+CvHqTMbhS/Vj8ArNu2/5Cy/dUUSVP/em9si33JAMdb8fX02/+Rcv/jwE4j+Kxa59q6osz8sszCAT7np8tjhw/yOd/S/7+18lhP27nPGuS815XHPzPC//6+Vta7pf2/v7bjrf/+nwFePkhcy0b5t9b6rP6rfP2W8vXl/cpdXu5/e/n6ivL1/H7lgiL5an1WqygS7k8Db6NIVqvimddW974hHm8bzXv24cPHyB72NEhqkm9RfLncrzXGneLX/K2AqzPzhk4az8zbgf+l+NLYfgvIVRRf1KC49elwtH6FHW75QUXEjIjYg2K4U6un4bRBip+TmYPdonJ/ip6Bn2TmgL0cmXkVcDvFr+a7tB1q9VZ8NzNvGqDeTym+UI5Uq5fo7My8bhT1R+PdFD3t91EML3qWzHwU+Mfy5X795xG0+ftB9reGNL1quAGVcyD2L1+eVMbQ31cphqcFbb1HY+QnwD3AGyJimzLGbYA3UHxu/1lVOTOTNXdHeoaiJ+tPKdaR+CFwfxRrN7xjGLG8aIjHeoNXlVQXkwZJjZGZD1EMZZnOmi9Yw5oA3S4i/iQizo2IWyPi0faJo8Cry2JbtJ33UYrhIgD/ERHHRcRrKr5MQvHFCGDfiPj3iNgvImYNN0agty2mlRS/6O5RHjsjM88cpF7VHIndy+e9IuK+wR7AS8tyL22r21rs6zIGV3XsOcohT63E5Acjqduh1nv5aWY+PUiZS8vn6RRDlvp7IIshcwNpzTvZeAQx/QHFEC+A3oEKZDH0bkn5snLxtU6V5/omRYJySLn7kPL1v1V8bu1tPJzF3ZG2oZj38l2KnjIovn/0AN+PiBOHaCeGeLi4mzQOTBokNU0rOTgkijsdHUAxpOjc4VSOiFMpfiU9iOKL2toUQ3Faq+e2Jg5P71f1UOAGiqFKfwf8CngoIr4fEe+Jfve0z8zLKMb4P0UxSfg7wPKIuCEiToiIbYcI9cG2mO4C/hv4V4rhPR+pqPf7imOtXo/1qf7ldp22ci2tyc/3VLR/d8WxgWzCmhtyDHbrzrHQei9V8d41QPl2KwfY19Ka27JORZnBYoLhxTVQTHVr/a29p+wJOaTf/mHJzDsz8+TM3D8zt6boGfwEa9ZT+URE7FtHwJLGjkmDpKb5EcUX470oJhPPBH6YmcuHqhgRbwf+imI8+3yKO9xMy8xZWU4cpZgoDcUvqn3KX5V3ohjaciZFAjEDeAfFnZ1+Hm23QC3r/B3F3Yz+FvgPiiFL2wNHA7+JiEEXq+PZi7u9NDNfm5kfKJORKlW/ALf+zT9lGL/eRmYuHOJcTTdRh7VMiLgy83qK5Hhbii/5LweuG2xo2wjavTMzT6KYP9MahjXUXZgkdZlJg6RGycynKHoVngd8odz99cFrPMuB5fNXM3NBZt5ajr1u96L+ldrPnZnfy8zDM/MVFL/cf5Lil+Wdgc8OUOf2zPxiZr6N4pf1ORRj/9cG/iUiXjjM2OvQmuuwZWWpgbV6MLaoKFN1bCAPUPTEQPHr83hpvZeqz+ElA5QfS+3nGE5c4xETrPnb+vt+rzuWmUspht1BkVxLmsBMGiQ1UWt4xDoUw3gWD7Ne6wvXrwY6GBFbUfyaOiyZeV9mnkBxS1BYsybDYOWfzswlwN4Uw6CmU9zidby05jv0RMUidoO4tnx+U0WZyvffXxaL1V1TvhzOhNhnVS+fR7OIWuu9vD76LcjXZq/y+RHgORO/x8BtrLmF7oArJEdEax4ArHkPY+3fKBK7dSh6sb5Zc/ut9SaeqLldSTUzaZDUOJl5DcXwohOBIzNz9TCrthap2nGQ48czwJfQKFYrrvpy2lpAa1pbnXUryj/BmmFE0yrK1e3brFnMrnJNhYjoP4n32+XzfgPNx4iI3alOKAbTSgDnRcROI6jXujtV5UrUg/guxR19ZlHcxvRZykTik62yw5n026myx+u75cuPD5LMHEqxTkmy5nqMdVy/oxhOdyJwTGbeO5x6EfGqiNhsiDIvYk1y9pxVyyVNLCYNkhqpHF50TGaOZFLmj8vnwyPi/a0v9hGxZUQsAg6m6Lno75XA9RFxZETMbiUQZTKxP8V4byjmLbScExFnR8Rb2xe2ioitgUUU49YfA346gvg7kpn3U8yvAPh/EXFW++JlEfH8iHhjRJwBXNmv+vnAbyiSnB9ExBvKOs+LiD+l+MJbtdjXYL5G8YVxGnBJRBzS+sIcEWtFxK5lnK/vV+9/y+f3DnEXq+fIzDso5qUAfDEiDisXmWutLv59ih6nR4HPj+I9jdbxFEndFhR3FdqujGlaRHwQOLUs97XMvHW8gsrMU8u/tZOHLt2nB7g9Ir4eEe+MiE1aByJig4j4S4qhSRtSJHCn1xq0pNqtPXQRSZo0FgLvA/6I4svqmRGxkjW/Vn+GYrXpgYbZvAI4qXysjohHynqtH1+u5tlfMNcD/pxykaqIWAGsy5o7Ej1NsbDYkBO465SZp0XEhhT3yz8UOLR8L09QfIFrvZ9l/eo9GREHUtzy8+XATyNiFbAWxYrat1CsbVB5+8wB4lkdEftQ3HL1VRQ9D2dHxEMUk9xbPTb9h8V8leIWskcCH4qI/6P4Bf6CzDxmGKc+GngZ8CcUKzuf3nZNoVjE7i/KcffjIjNvjYiDKdYj6QFuLD+H6ay5E9MlFO95onuS4m/gPeWD8r+XpLiuLY8DH8rMXw7WUHkb4Cq/zczXdRaupKHY0yBpysjMJ4A3A1+kGEP+DMV47R8D7yzvdjSQGyhu7fplylutAhtQDHe6guKOTHtkZvsv7f8P+GuKuz3dRvHldy3gVuBsYOfMrG1S6Uhk5ucp1qM4E7iZ4v8F04F7KXpL/ppihef+9X5DsejdV8uy61As9HUS8DrW3EJzpPH8lmJux8coPs+VFHemasVzKPCLfnXOBj5Y7n+KYk2JrYBNh3nOR4G3l23/lKJXobXi9leBHTPzosFbGBuZuZhi+NxZFInb+mVsV1AMpXprZj4yaAMTRGZ+heLmAMdSrFlyB8V/L88H7gf+i6JnZYfMXDREc0Mt7jYet5+Vprx47o1DJEmSJGkNexokSZIkVTJpkCRJklTJpEGSJElSJZMGSZIkSZVMGiRJkiRVMmmQJEmSVMmkQZIkSVIlkwZJkiRJlUwaJEmSJFUyaZAkSZJUae1uBzAVRcTtwAbAsi6HIkmSpMlta+DhzNymk0ZMGrpjg+c///mb7LDDDpt0O5DJYuXKlQDMnDmzy5GoE17HcXDvvWu2N9+89ua9hs3nNWw+r2Hz1XkNb7jhBh577LGO2zFp6I5lO+ywwybXXHNNt+OYNJYsWQJAT09PV+NQZ7yO4yBizfY999TevNew+byGzec1bL46r+Euu+zCtddeu6zTdpzTIEmSJKmSSYMkSZKkSiYNkiRJkiqZNEiSJEmq5ERoSZpKrr662xFIkhrIpEGSppJddul2BJKkBnJ4kiRJkqRKJg2SJEmSKpk0SJIkSarknAZJmkraV4TO7F4ckqRGsadBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJpEGSJElSJZMGSZIkSZVMGiRJkiRVMmmQJEmSVMnF3SSpoeYsmjPiOr1jEIckafKzp0GSJElSJXsaJGkKOeCk3QC44M8u6HIkkqQmMWmQpCnk/o2nFRtbbNHdQCRJjeLwJEmSJEmVTBokSZIkVTJpkKQpZNaDq5n14Gq4555uhyJJahDnNEjSFHLBUVcVG0e9GDK7G4wkqTHsaZAkSZJUyaRBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJpEGSJElSJZMGSZIkSZVMGiRJkiRVMmmQJEmSVMmkQZIkSVKltbsdgCRp/MxZ2ANA79ze7gYiSWoUexokSZIkVTJpkCRJklTJpEGSJElSJZMGSZpCZi9byexlK+Gaa7odiiSpQZwILUlTyFfml8nC/F0hs7vBSJIaw54GSZIkSZVMGiRJkiRVMmmQJEmSVMmkQZIkSVIlkwZJkiRJlbx7kiR10ZxFc7odgiRJQ7KnQZIkSVIlkwZJkiRJlUwaJEmSJFVyToMkTSHLN1oXgE2fP6vLkUiSmsSkQZKmkANP3h2A3rm9XY5EktQkDk+SJEmSVKnxSUNEvCcisnwcOkiZvSNiSUSsiIhVEfHziJg7RLtzI+IXZfkVZf29x+ZdSJIkSRNXo5OGiHgpcDqwqqLMEcBi4FXAN4CzgC2AhRFxwiB1TgAWApuX5b8B7AgsLtuTJEmSpozGJg0REcDZwP3AlwcpszVwAvAAsGtmfjQzjwJ2Am4Fjo6I3frV2R04ujy+U2YelZkfBXYp2zmhbFeSGme3Xy1nt18th8WLux2KJKlBGps0AB8D9gLeBzwySJn3A9OA0zNzWWtnZj4IHF++/FC/Oq3XXyjLteosA75Utve+DmOXpK44/pTrOf6U62GffbodiiSpQRqZNETEDsAXgVMy8/KKonuVzz8a4NgP+5XppI4kSZI0aTXulqsRsTbwdeBO4FNDFN+ufF7a/0Bm3hsRjwAviYj1M/PRiJgOvBhYlZn3DtDezeXz7GHGes0gh7ZfuXIlS5YsGU4zGoaVK1cC+Jk23FS8jgfPOHicz7hkzdYYfM5T8RpONl7D5vMaNl+d17DVVqcalzQAnwFeC7whMx8bouyG5fOKQY6vAKaX5R4dZnmAjYYXqiRJktR8jUoaIuL1FL0LJ2bmVd2OZyiZuctA+yPimpkzZ+7c09MzzhFNXq1M3M+02abidVywaMG4nu+wtu2x+Jyn4jWcbLyGzec1bL46r+HMmTM7bgMaNKehHJZ0DsVQo08Ps1qrZ2DDQY7371kYbvmHhnl+SZIkqfEakzQAMyjmEuwAPN62oFsCny3LnFXuO7l8fVP5/Jw5CBGxOcXQpLsy81GAzHwEuBuYUR7vb9vy+TlzJCRJkqTJqknDk1YDXxvk2M4U8xyuoEgUWkOXLgX2AN7Wtq/l7W1l2l0KHFLWOXuYdSRJkqRJqzFJQznp+dCBjkXEfIqkYVFmfrXt0NnAXwNHRMTZrbUaImJj1tx5qf/CcF+mSBqOjYjvtdZqKBd0+yhF8tI/mZAkSZImrcYkDaORmbdHxCeBU4GrI+J84AngAOAlDDChOjOvjIh/Bj4BXBcRFwDrAn8ObAL8VftCcZIkSdJkN6mTBoDMPC0ilgHHAO+lmMfxG+C4zFw0SJ2jI+J/KHoWDgOeAa4F/ikzLx6XwCVpDCzdagYAs2cNa7kZSZKASZI0ZOZ8YH7F8cXA4hG2uRBY2EFYkjThHL5gVwB65/Z2ORJJUpM06e5JkiRJkrrApEGSJElSJZMGSZIkSZUmxZwGSdLw7L3knmJj9Zlw2GHdDUaS1BgmDZI0hRy9sFzQfuHhJg2SpGFzeJIkSZKkSiYNkiRJkiqZNEiSJEmqZNIgSZIkqZJJgyRJkqRKJg2SJEmSKpk0SJIkSapk0iBJkiSpkkmDJEmSpEquCC1JU8iVr54FwO4v3a3LkUiSmsSkQZKmkGOP2hGA3rmLuxyJJKlJHJ4kSZIkqZI9DZLUgTmL5nQ7BEmSxpw9DZIkSZIq2dMgSVPI3AtvLzZunw/z53czFElSg9jTIElTyLyL7mDeRXfAggXdDkWS1CAmDZIkSZIqmTRIkiRJqmTSIEmSJKmSE6ElaYoa7e1ie+f21hyJJGmis6dBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJpEGSJElSJe+eJElTyMV7bt7tECRJDWTSIElTyInv267bIUiSGsjhSZIkSZIqmTRIkiRJqmTSIEmSJKmScxokaQo5+uyb+rad3yBJGi6TBkmaQva+7N6+bZMGSdJwOTxJkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJpEGSJElSJZMGSZIkSZVMGiRJkiRVMmmQJEmSVMmkQZIkSVIlV4SWpClk4b5bdTsESVIDmTRI0hSy6N3bdDsESVIDOTxJkiRJUiWTBkmSJEmVTBokSZIkVXJOgyRNIV846X/6to89asdRtTFn0ZxBjx0842AAFixaMODx3rm9ozqnJKm7TBokTXlVX4Inm91/fX+3Q5AkNZDDkyRJkiRVMmmQJEmSVMmkQZIkSVIlkwZJkiRJlUwaJEmSJFUyaZAkSZJUyaRBkiRJUiWTBkmSJEmVTBokSZIkVXJFaEmaQk6cN7vbIUiSGsikQZKmkIt7tuh2CJKkBnJ4kiRJkqRKJg2SJEmSKpk0SJIkSarknAZJmkK+8tmr+7YPX7BrFyORJDWJSYMkTSGz71jV7RAkSQ3k8CRJkiRJlUwaJEmSJFUyaZAkSZJUyaRBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJpEGSJElSJZMGSZIkSZVcEVqSppBPffxV3Q5BktRAjetpiIh/iIhLIuK3EfFYRDwQEb+KiM9GxKxB6uweET8oyz4WEddFxJERsVbFefaOiCURsSIiVkXEzyNi7ti9M0kae1e9dtO+hyRJw9W4pAE4CpgO/Bg4Bfgm8BQwH7guIl7aXjgi9gUuB94EXAicDqwLnAScN9AJIuIIYDHwKuAbwFnAFsDCiDih9nckSZIkTWBNHJ60QWY+3n9nRHwB+BTwt8BHyn0bUHzhfxroycyry/2fBi4FDoiIgzLzvLZ2tgZOAB4Ads3MZeX+zwG/BI6OiO9k5lVj9QYlSZKkiaRxScNACUPpWxRJw7Zt+w4AXgCc00oYWm1ExHHAJcCHeXaPw/uBacA/tBKGss6DEXE88DXgQ4BJgzSBzFk0p9shSJI0aTUuaajwzvL5urZ9e5XPPxqg/OXAo8DuETEtM1cPo84P+5WpFBHXDHJo+5UrV7JkyZLhNKNhWLlyJYCfacN1ch0PnnFwzdFMTn/5wb/u2/7mWf9Ye/ubrLUJMPj18G904vPf0+bzGjZfndew1VanGps0RMQxwAxgQ2BX4A0UCcMX24ptVz4v7V8/M5+KiNuBVwJ/ANwwjDr3RsQjwEsiYv3MfLSO9yJJ42X6gyu6HYIkqYEamzQAxwAvanv9I2BeZv6+bd+G5fNg/5ds7d9ohHWml+Uqk4bM3GWg/RFxzcyZM3fu6empqq4RaGXifqbN1sl1XLBoQb3BTFKHtW2fu+rc2ttv9TAM1nbv/r21n1P18t/T5vMaNl+d13DmzJkdtwHNvHsSAJm5WWYGsBmwH0Vvwa8iYufuRiZJkiRNLo1NGloy83eZeSHwFmAWcE7b4VZvwYbPqfjs/Q+Noo59/JIkSZoSGp80tGTmHcBvgFdGRGvVopvK59n9y0fE2sA2FGs83NZ2qKrO5hRDk+5yPoMkSZKmikmTNJS2KJ+fLp8vLZ/fNkDZNwHrA1e23TlpqDpv71dGkiRJmvQalTRExOyIeM6woYh4Xrm42wspkoAHy0MXAMuBgyJi17by6wGfL1+e0a+5s4HVwBHlQm+tOhtTrAMB8OXO340kSZLUDE27e9I7gL+PiCuA24H7Ke6gtCfFROj7gA+2CmfmwxHxQYrkYUlEnEex0vM+FLdWvQA4v/0EmXl7RHwSOBW4OiLOB56gWCjuJcCJrgYtSZKkqaRpScNPgJdTrMnwWopbpT5CsabC14FTM/OB9gqZ+b2I2BM4FtgfWA+4BfhEWT77nyQzT4uIZRS3dX0vRY/Mb4DjMnPR2Lw1SZIkaWJqVNKQmdcDR4yi3s8oeilGUmcxsHik55IkSZImm0YlDZKkzhw+f8A1JyVJqlRr0lBOFt4cuLX9jkQR8T7gXRRDiU7OzF/UeV5J0vAs3bqelUElSVNL3T0NxwPvobiLEQAR8VfAyUCUu94VEbtm5m9qPrckSZKkMVD3LVf3AC7JzMfa9h0D3E2xLsKflfs+UfN5JUmSJI2RunsaXgxc0noREa8AXgr8TWZeUe47kCKBkCRJktQAdScNzwceb3u9B5AUt0ptuRXYu+bzSpKGoXfekr7tOQt7uhaHJKlZ6h6edDewfdvrtwIPA79u27cx0D58SZIkSdIEVndPQy8wNyKOoOhx2Af4TmY+01bmZcBvaz6vJKkB5iya01H93rm9NUUiSRqJunsa/h5YBZwCnEmROMxvHYyIDShWc76y5vNKkiRJGiO19jRk5u0R8UrggHLXv2fmnW1FXg58Bfi3Os8rSZIkaezUviJ0Zt4HnD7IsWuBa+s+pyRJkqSxU/fwJEmSJEmTTO09DRGxDrAv8IcUd0paa4BimZkfqPvckiRJkupXa9IQEVsAP6a47WpUFE3ApEGSJElqgLp7Gk4EdgDOBc6iuLXqUzWfQ5IkSdI4qjtpeAtweWb+Zc3tSpIkSeqSupOG9YCf19ymJKkmB5y0W7dD6Egni8O5MJwkjV7dScP1wFY1tylJqsn9G0/rdgiSpAaq+5ar/wTsExGvqLldSZIkSV1Sd0/D/wGLgSsj4hTgGuChgQpm5uU1n1uSJEnSGKg7aVhCcTvVAD5dbg9moPUbJEljaNaDq/u2HaokSRquupOGz1GdKEiSuuiCo67q256zsKd7gUjEMOy5AAAgAElEQVSSGqXWpCEz59fZniRJkqTuq3sitCRJkqRJpu7hSX0i4g3Aa4GNgBXAtZl5xVidT5IkSdLYqD1piIhdgK8D27V2Uc5ziIibgPdm5tV1n1eSJEnS2Kg1aYiIlwOXABsAVwCXAvcCmwN7AW8AfhwRf5iZN9d5bkmSJEljo+6ehk8DM4E/z8xv9zs2PyIOAM4DjgPm1nxuSZIkSWOg7onQbwYuHCBhACAzLwAuKstJkiRJaoC6k4ZNgRuHKHNjWU6SJElSA9SdNPweeMUQZbYHltd8XkmSJEljpO6k4VJgn4g4aKCDEbE/sC/wk5rPK0mSJGmM1D0R+nMUScE3I+KjQC/F3ZM2A3oo7p60Evh8zeeVJA3DnIU93Q5BktRAtSYNmXlLRLwZOAfYo3wkxVoNADcBc73dqiRJktQctS/ulpm/BHaIiN2BnYENKVaE/lVm/qzu80mSJEkaW7UnDS2ZeSVw5Vi1L0mSJGl8jFnSIEmaeGYvW9m3vXTrmV2MRJLUJB0lDRHxGYo5C1/KzAfK18ORmfl3nZxbkjRyX5l/Td+2k6IlScPVaU/DfIqk4XzggfL1cCRg0iBJkiQ1QKdJw5zy+c5+ryVJkiRNEh0lDZl5WdVrSZIkSc1X64rQEfHeiNhpiDKvioj31nleSZIkSWOn1qQBWAi8a4gy+wJn13xeSZIkSWOk7qRhONaimAgtSZIkqQG6kTTMBh7swnklSZIkjULHi7tFxL/22/WuiNh6gKJrAVsCbwS+3+l5JUmSJI2POlaEnte2ncBrysdAEvg5cFQN55UkSZI0DupIGrYpnwO4DTgZOGWAck8DD2bmIzWcU5I0Css3WrfbIUiSGqjjpCEz72htR8QCoLd9nyRp4jjw5N27HYIkqYHq6Gnok5kL6mxPkiRJUvfVvbjbgRFxaURsMcjxF0fEJRGxX53nlSRJkjR26r7l6qHARpl5z0AHM/NuYMOynCRJkqQGqHV4ErAjcPEQZX4JvLPm80qShmG3Xy3v277qtZt2MRJJUpPUnTRsAvzfEGXuB/w/lSR1wfGnXN+3PWdhT/cCkSQ1St3Dk5YD2w5RZlvgoZrPK0mSJGmM1N3T8DNgn4jYPjNv7H8wInYA9gUW13xeSZPA0vuXArBgkTdikyRpIqm7p+EEikTkioj4WETMjojp5fPHgZ8Ca5XlJEmSJDVA3es0/DIiPgJ8CTipfLR7GvhwZv68zvNKkiRJGjt1D08iM8+KiCuAjwCvBzaimMPwX8AZmXlD3eeUJEmSNHZqTxoAysTgr8aibUmSJEnjq+45DZIkSZImmY56GiJiy3Lz7sx8uu31kDLzzk7OLUmSJGl8dDo8aRmQwA7A0rbXQ8kazi1JkiRpHHT6xf0cigRgRb/XkqQJaOlWM7odgiSpgTpKGjJzXtVrSdLEcviCXbsdgiSpgZwILUmSJKmSSYMkSZKkSp3ePelfR1k1M/MDnZxbkiRJ0vjodCL0vEH2JxAV+xMwaZCkcbb3knv6ti/u2aKLkUiSmqTTpGGbfq+fB5wEvBE4FVgC3AdsBsyhWCX6cuATHZ5XkjQKRy9c2rdt0iBJGq5O7550R/vriDiKImHYud+xm4DLImIRcA2wL3ByJ+eWJEmSND7qngh9GPCt/slES2beDny7LCdJkiSpAepOGrYGHhqizINlOUmSJEkNUHfSsBx462AHIyLK4/fXfF5JkiRJY6TupOHbwGsi4lsR8axJ0uXr84GdymdJkiRJDdDp3ZP6+wzwBuAA4N0RcTfwO+BFwIuBtYBfAvNrPq8kSZKkMVJrT0NmrqJIGo4DlgFbAq8rn28HjgXeWJaTJEmS1AB19zSQmU8AxwPHR8QMYENghYmCJEmS1Ex1z2l4lsxclZl315UwRMSsiDg0Ii6MiFsi4rGIWBERV0TEByJiwPcTEbtHxA8i4oGyznURcWRErFVxrr0jYknZ/qqI+HlEzK3jfUiSJElNUntPA0BEvADYH9gBmJ6Zh7bt3wb4n8x8bBRNHwicAdwL9AJ3UsyX2A/4KvD2iDgwM7Mtln2B7wCPU0zAfgB4J8XK1XuUbfaP/wjgNIq7PH0DeIJinsbCiNgxM48ZReyS1HVXvnpWt0OQJDVQ7UlDRHwAOBVYDwgggUPLwy8CrqJY3O1ro2h+KbAP8P3MfKbtnJ8CfkGRqOxHkSQQERsAZwFPAz2ZeXW5/9PApcABEXFQZp7X1tbWwAkUycWumbms3P85ikncR0fEdzLzqlHEL016cxbNGXXdg2ccXGMkGsixR+3Y7RAkSQ1U6/CkiPgT4EyKL/fvpugV6JOZ1wP/C7xrNO1n5qWZubg9YSj33wd8uXzZ03boAOAFwHmthKEs/zjFZG2AD/c7zfuBacDprYShrPMgxVwNgA+NJn5JkiSpieruafgbiqFDe2bmwxHx2gHKXAfsVvN5AZ4sn59q27dX+fyjAcpfDjwK7B4R0zJz9TDq/LBfmUoRcc0gh7ZfuXIlS5YsGU4zGoaVK1cC+JlOAJ30Fmyy1iYdt6HumsjX0H8fhsd/T5vPa9h8dV7DVludqnsi9K7AxZn5cEWZu4DN6jxpRKwNvLd82f5lf7vyeWn/Opn5FMVtYNcG/mCYde4FHgFeEhHrdxi2JEmS1Ah19zSsS/GluspGFHMM6vRF4FXADzLzP9r2b1g+rxikXmv/RiOsM70s92hVUJm5y0D7I+KamTNn7tzT01NVXSPQysT9TLtvwaIFo67b+nX63FXn1hWO+pl74e1924vevU3t7U/ka9i7f2+3Q2gE/z1tPq9h89V5DWfOnNlxG1B/0rAMGPCLcpvXAzfVdcKI+BhwNHAjcEhd7UrSZDTvojv6tsciaZAkTU51D0+6CHhjRDznNqYAEfE+YCfKuxt1qrw16inAb4A5mflAvyKt3oINGVhr/0OjqDNYT4QkSZI0qdSdNPwjxdoJ50bE+ZQTniPiiPL1mcDNFGsgdCQijizbuZ4iYbhvgGKtHo3ZA9Rfm2LNiKeA24ZZZ3OKoUl3ZWbl0CRJkiRpsqg1aShvS7oncAXFomlvoVir4dTy9ZXAH2fmUPMeKkXE31AszvbfFAnD/w1S9NLy+W0DHHsTsD5wZdudk4aq8/Z+ZSRJkqRJr+6eBjLzzszsAV5DsQbCccBfAa/LzD0z8+5O2i8XZvsicA1FArK8ovgFwHLgoIjYta2N9YDPly/P6FfnbGA1cES50FurzsbAp8qXX0aSJEmaImqdCB0RbwIezsz/zszrKNZkqLP9ucDnKO6+9FPgYxHRv9iyzFwIUK4V8UGK5GFJRJxHsdLzPhS3Vr0AOL+9cmbeHhGfpOgdubocVvUExUJxLwFOdDVoSWqeTlYr753rnZckTW113z2pF/gK8JGa221p3epjLeDIQcpcBixsvcjM70XEnsCxwP7AesAtwCeAUzMz+zeQmadFxDLgGIr1H55HMdn6uMxcVMs7kSRJkhqi7qRhOfBYzW32ycz5wPxR1PsZ8I4R1lkMLB7puSRJkqTJpu45DUuA3WtuU5IkSVIX1Z00HAdsFxF/FxHr1Ny2JEmSpC6oe3jS31Ksm/Ap4AMR8WvgPqD/vIHMzA/UfG5J0hAu3nPzbocgSWqgupOGeW3bm5WPgSRg0iBJ4+zE923X7RAkSQ1Ud9KwzdBFJEmSJDVJrUlDZt5RZ3uSJEmSuq+2pCEitgReRzH06JeZ+du62pYkSZLUPbUkDRFxAsVia63lmTMiTsrMT9bRviSpHkeffVPftvMbJEnD1XHSEBEHU6yunMCNFInDdsAnIuLazDy303NIkuqx92X39m2bNEiShquOdRoOBZ4C3pyZr8zMVwBvBZ7BOyRJkiRJjVdH0rATcFFm9rZ2ZOZPgIuA19TQviRJkqQuqiNp2JhiWFJ/NwIb1dC+JEmSpC6qI2l4HvDkAPufZM3EaEmSJEkNVUfSAMUkaEmSJEmTUF3rNMyPiPkDHYiIpwfYnZlZ92rUkiRJksZAXV/cRzoMyWFLkiRJUkN0nDRkZl1DnCRJkiRNQH7hlyRJklTJeQWSNIUs3HerbocgSWogkwZJmkIWvXubbocgSWoghydJkiRJqmTSIEmSJKmSSYMkSZKkSs5pkKQp5Asn/U/f9rFH7djFSCRJTWLSIElTyO6/vr/bIUiSGsjhSZIkSZIq2dMgSdIQ5iyaM+q6vXN7a4xEkrrDngZJkiRJlUwaJEmSJFUyaZAkSZJUyaRBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJdRokaQo5cd7sbocgSWogkwZJmkIu7tmi2yFIkhrI4UmSJEmSKpk0SJIkSapk0iBJkiSpknMaJGkK+cpnr+7bPnzBrl2MRJLUJCYNkjSFzL5jVbdDkCQ1kMOTJEmSJFUyaZAkSZJUyaRBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJW65KepY5i+Z0OwRJkjTB2NMgSZIkqZJJgyRJkqRKDk+SpCnkUx9/VbdDkCQ1kEmDJE0hV712026HIElqIIcnSZIkSapk0iBJkiSpkkmDJEmSpErOaZCkKeTbR17Zt33gybt3MRJJUpOYNEjSFLLpQ090OwRJUgM5PEmSJElSJZMGSZIkSZUcniRJ0hias2hOR/V75/bWFIkkjZ49DZIkSZIqmTRIkiRJqmTSIEmSJKmSSYMkSZKkSiYNkiRJkiqZNEiSJEmq5C1XJWkKOXz+Lt0OQZLUQCYNkjSFLN16ZrdDkCQ1kMOTJEmSJFUyaZAkSZJUyaRBkiRJUiXnNEjSFNI7b0nf9pyFPV2LQ5LULPY0SJIkSapk0iBJkiSpkkmDJEmSpEomDZIkSZIqORFakqQJbM6iOaOu2zu3t8ZIJE1l9jRIkiRJqtS4pCEiDoiI0yLipxHxcERkRHxjiDq7R8QPIuKBiHgsIq6LiCMjYq2KOntHxJKIWBERqyLi5xExt/53JEmSJE1sTRyedBzwamAVcBewfVXhiNgX+A7wOHA+8ADwTuAkYA/gwAHqHAGcBtwPfAN4AjgAWBgRO2bmMXW9GUmSJGmia1xPA3AUMBvYAPhwVcGI2AA4C3ga6MnMD2TmJ4HXAFcBB0TEQf3qbA2cQJFc7JqZH83Mo4CdgFuBoyNit1rfkSRJkjSBNa6nITP7ZnVFxFDFDwBeAJyTmVe3tfF4RBwHXEKReJzXVuf9wDTgHzJzWVudByPieOBrwIcokg5pQupk4qQkSVJ/jUsaRmiv8vlHAxy7HHgU2D0ipmXm6mHU+WG/MpLUKAecZEepJGnkIjO7HcOoRUQP0At8MzPfM8DxXwK7UgwzumaA49cDrwRekZk3lPt+D2wKbJqZ9w9QZxUwHZiemY8OEd9zzlnaftttt13/zDPPrKquEVi5ciUAM2fO7HIkE8PS+5d2O4RR2WStTQB44OkHuhyJRstrOLHMnjV7xHX897T5vIbNV+c1POyww7j55puvzcxdOmmniXMaRmLD8nnFIMdb+zcaRZ0NBzkuSZIkTSqTfXhSVw2W0UXENTNnzty5p6dnnCOavJYsWQKAn2lhwaIF3Q5hVA6ecTAA5646t8uRaLS8hhNL7/4jX9zNf0+bz2vYfHVew7p6nCZ70jBUr0Br/0P96mxaHnvO8CSG7omQpAlr1oOr+7bv33haFyORJDXJZE8abqKY0zAbeNb8gohYG9gGeAq4rV+dTcs6V/WrsznFfIa7hprPIEkT0QVHrflnbc7Cnu4FIklqlMk+p+HS8vltAxx7E7A+cGXbnZOGqvP2fmUkSZKkSW+yJw0XAMuBgyJi19bOiFgP+Hz58ox+dc4GVgNHlAu9tepsDHyqfPnlMYpXkiRJmnAaNzwpIt4FvKt8uVn5vFtELCy3l2fmMQCZ+XBEfJAieVgSEedRrPS8D7Bduf/89vYz8/aI+CRwKnB1RJwPPEGxUNxLgBMz04XdJEmSNGU0LmkAXgPM7bfvD8oHwB3AMa0Dmfm9iNgTOBbYH1gPuAX4BHBqDrBQRWaeFhHLynbeS9Ej8xvguMxcVOu7kSRJkia4xiUNmTkfmD/COj8D3jHCOouBxSOpI0mSJE1Gk31OgyRJkqQOmTRIkiRJqmTSIEmSJKmSSYMkSZKkSiYNkiRJkio17u5JkqTRm7Owp9shSJIayJ4GSZIkSZVMGiRJkiRVMmmQJEmSVMk5DZI0hcxetrJve+nWM7sYiSSpSUwaJGkK+cr8a/q2nRQtSRouhydJkiRJqmTSIEmSJKmSSYMkSZKkSiYNkiRJkiqZNEiSJEmqZNIgSZIkqZJJgyRJkqRKJg2SJEmSKpk0SJIkSarkitCSNIUs32jdbocgSWogkwZJmkIOPHn3bocgSWoghydJkiRJqmRPgyRJk9ScRXNGXOfgGQcD0ENPzdFIajJ7GiRJkiRVsqdBkqaQ3X61vG/7qtdu2sVIJElNYtIgSVPI8adc37c9Z2FP9wKRJDWKw5MkSZIkVTJpkCRJklTJpEGSJElSJec0SBPUaG6VKEmSNBbsaZAkSZJUyaRBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJuydJ0hSydKsZ3Q5BktRAJg2SNIUcvmDXbocgSWoghydJkiRJqmTSIEmSJKmSSYMkSZKkSs5pkKQpZO8l9/RtX9yzRRcjkSQ1iUmDJE0hRy9c2rdt0qAqcxbNGXXd3rm9NUYiaSJweJIkSZKkSvY0SJKkWtlLIU0+9jRIkiRJqmTSIEmSJKmSSYMkSZKkSiYNkiRJkiqZNEiSJEmqZNIgSZIkqZJJgyRJkqRKrtMgSVPIla+e1e0QJEkNZNIgjaFOFjiSxsKxR+3Y7RAkSQ3k8CRJkiRJlexpkCrYUyBJkmRPgyRJkqQh2NMgSVPI3Atv79te9O5tuhiJJKlJTBokaQqZd9EdfdsmDZKk4XJ4kiRJkqRKJg2SJEmSKpk0SJIkSapk0iBJkiSpkhOhJUnShNHp+ji9c3trikRSO3saJEmSJFUyaZAkSZJUyeFJkiRp0uhkeJNDm6TB2dMgSZIkqZI9DZI0hVy85+bdDkGS1EAmDZI0hZz4vu26HYIkqYEcniRJkiSpkj0NkiRJHXICtiY7kwZNep0uFCRJkjTVmTRI0hRy9Nk39W07v0F6Nn9kkgZn0iBJU8jel93bt23SIEkaLidCS5IkSapkT4PGzVh2+x4842AAFixaMGbnkCRJmqpMGiRJkrqo0x/VvPuSxoPDkwYRES+JiH+NiHsiYnVELIuIkyNi427HJkmSJI0nexoGEBEvA64EXghcBNwI/CHwceBtEbFHZt7fxRC7xjtLSJIkTT0mDQP7F4qE4WOZeVprZ0T8M3AU8AXgQ12KrSN+6ZckaXLp///28Zrn57CoqcWkoZ+yl+EtwDLgS/0OfxY4DDgkIo7OzEfGOTxJkqQJwVWwpxaThudq/QX8Z2Y+034gM1dGxM8okoo/Ai4Z7+AkSZKmsm5OHJ/KiVJkZrdjmFAi4p+AY4BjMvPEAY6fDnwU+EhmnjFEW9cMcujV06ZNW2vLLbfsON6RWv306nE/53hYi7UAeJqnuxyJOuF1HHub3nZn3/byP6j/3yCvYfN5DZuvCddw2lrTRl230+8y3Tr3SM77zDPF79bPe17n9yy68847Wb169QOZOauTduxpeK4Ny+cVgxxv7d+og3M8vXr16hU333zzsg7a0LNtXz7f2NUo1Cmv4xi7s/3FbXcOVqwTXsPm8xo2n9ew+eq8hlsDD3faiEnDGMrMXbodw1TR6tXxM282r2PzeQ2bz2vYfF7D5puI19B1Gp6r1ZOw4SDHW/sfGodYJEmSpK4zaXium8rn2YMc37Z8XjoOsUiSJEldZ9LwXK2p7W+JiGd9PhExE9gDeBT4r/EOTJIkSeoGk4Z+MvNW4D8pJo18tN/hBcB04Ouu0SBJkqSpwonQA/sIcCVwakT8MXAD8HqKNRyWAsd2MTZJkiRpXLlOwyAi4qXA54C3AbOAe4ELgQWZ+WA3Y5MkSZLGk0mDJEmSpErOaZAkSZJUyaRBkiRJUiWTBkmSJEmVTBokSZIkVTJpkCRJklTJpEGSJElSJZMGTUgRsSwicpDHfSNo54CIOC0ifhoRD5f1vzGWsatQxzWMiFkRcWhEXBgRt0TEYxGxIiKuiIgPRIT/ho2hGv8O/yEiLomI35bX8IGI+FVEfDYiZo3le1B913GAdt/T1s6hdcasZ6vxb3FM/lvQ0Or+7CPij8v/N94XEasj4p6I+I+IeMdYxA+uCK2JbQVw8gD7V42gjeOAV5d17gK2ryEuDV+n1/BA4AyKxRV7gTuBFwH7AV8F3h4RB6YLzoylOv4OjwKuBX4M/B8wHfgjYD5wWET8UWb+tsM4Va2O69inXAD19LL+jA7i0vDVdQ1r/W9BI1LLZx8R/wh8kuJ7zb8Dy4EXALsAPcAPOopysPP6/1pNRBGxDCAzt+6wnTkUf1S3AHtSfPH8Zma+p8MQNYQ6rmFE7EXxBfP7mflM2/7NgF8ALwUOyMzvdBSsBlTj3+F6mfn4APu/AHwKOCMzP9LJOTS4uq5jW3tBkQBuA3wXOAb4YGZ+tY729Vw1/i3W0o5GrsZr+EHgTGARcFhmPtHv+DqZ+WQn5xiMXfua1DKzNzNv9pfoZsrMSzNzcXvCUO6/D/hy+bJn3APTiAyUMJS+VT5vO16xqBYfA/YC3gc80uVYpCkjIqbx/9u793A7qvKO499fEJSGmwQBicUULRUUlEsFCsSkCOEakKeUFn0waPL4WGhMNRRLa0kthWAFCWmrJlpTwkWESjUFUysGkURAIJh6aUAg4SJguYR7goS3f6y1yWTO3nPOPmd29j6c3+d59rNO9qyZ885emTPz7llrDfwD6a57n4QBoFMJA7h7kvW210v6ELAr6cS0ArgpItZ3NyxrQyfbsPGH8eUatmWtdbINj8vlihq2ZdVqaUdJewCzgTkRcVO+G2ibRl3Hos+t3TPUz/5wUjeki4FXJB0DvAtYC9wWET/qQMyvctJgvWxnYGHpvfslnRYRP+hGQNa2jrShpNcBp+Z/Lh7sdmxAamtDSTNJ/d+3BfYHDiGdNGfXEahVGnI75uNuIelbzrNrjs/6V9ex6HNr9wz1s//9XK4FlpMShldJuonUZff/hhxpE+6eZL3qa8BhpANsNLAX8GVgHPAdSe/uXmg2QJ1sw9mkP5bXR8R/DTFOa63uNpwJnAPMICUMi4EjOnWCs1fV1Y5/C+wDTImIFzsQp7VWVxv63No9dXz2O+byTCCAQ4Gtgb2B7wLjgatrjbooIvzya9i8gM/nA+XaQaw7Ia97Wbf3YyS/htKGef3pef1fANt3e39G4quGNtwJ+ACwEvgVsG+392kkvtppR+AAUlfAz5Xen5W3MbXb+zMSX0M9Fuvejl+d/exJSUaQ7jSMKy37LeDBvPygTsTqOw023DQGv47vahQ2FINuQ0lnAHOAnwMTI+LJOgOzARvScRgRj0XEtcARwBjg0roCs7YMqB1zt6RLgbuBz3Q6KGtLXedEn1u7p53Pfk0ul0fEquKCiHgBaNx5f289oW3MSYMNN41uDKO7GoUNxaDaUNIMYC7wU1LC4AcRdU8tx2FErCYlgO+UtMOQo7J2DbQdtwJ2B/YA1hYfSkXqbgYwP7/XbA5665y6zok+t3ZPO5/9ylyuabH8qVxuOaSIWvBAaBtuDszlfV2Nwoai7TaUdBZpHMNdwOER8XgnArMBq/M43CWXnrll0xtoO64Dvtpi2b6kcQ43ky5oOjp7i/VR17Hoc2v3tPPZ30DqfrSnpFFRmo6cDQOj768ruCInDdZz8pR+D0TE86X3x5GeQApwWeH9zYG3Ab+JiHs3UZhWoc42lPQZ4LPAHaRBs+6StAnU1YaSdgcei4inS9sZBfw9aWDfsoh4CqtdHe0YadDz1Bbbn0VKGv4t/HC3jqjxWGxrO1afutowIlZLWgRMBj4BfKGwzhHAJNJdiI7MKuikwXrRycCn8tRhq4FnSQfPMcAbSI9H/3yh/ljSoNjVpFkIXiXpBOCE/M+dc3mQpAX558cjYmb9uzDi1dKGkj5MShjWAz8EpqeH0W5kVUQs6MROjHB1HYdHA+dLupn07dcTpIHQ7wN2Ax4FpnVyR0a42v6eWtfU1YbtbsfqU+dxeDopUb8oP6dhOenp7CeQzpVTy1/S1MVJg/WiJcDvkQ6Kg0n9/NaQbn8vBBZGnipgAN4DfLj03m75BemAdNJQv7ra8HdyuRlpms5mfgAsGEqw1lRdbfg94O2kKVb3AbYjPdTo7rydS3z3qKPq/Htq3VFXG/r/QvfU9tlHxEOS9iNNgTyZNID6GWARcH5E3FZ/+In8/8PMzMzMzKp49iQzMzMzM6vkpMHMzMzMzCo5aTAzMzMzs0pOGszMzMzMrJKTBjMzMzMzq+SkwczMzMzMKjlpMDMzMzOzSk4azMzMzMyskpMGMzMzMzOr5KTBzMzMzMwqOWkwMzMzM7NKThrMzMzMzKySkwYzMxs2JO0u6SVJf9ntWNol6URJIemwbsdiZtYuJw1mZq9h+SI1JL0i6W0V9ZYU6k7ZhCG26yLgCeCfmi2UNFrSGZIWS3pE0jpJz0m6W9KVkv5U0uaD/eWSpuXP6BsDqHt2rjsnv3UtcCdwkSSff81sWPEfLTOz176XAQEfbbZQ0u8CE3K9niXpD4BjgLkR8UKL5f8LzAXeAywBLga+CCwHJgJXAMuGEMaVwHPA8ZJ2qIi1+HnPA4iIAC4A9gb+ZAgxmJltck4azMxe+x4DbgdOk/S6Jsun5nLRpgtpUE4HXgEuLS+Q9E5gMbAL8NfArhFxSkScFRFnRsTJwFjgJNJF/6BExHOkxGEL4NSKqn8I7AYsi4ifFd7/NrAG+LPBxmBm1g1OGszMRob5wM7AscU3c1edKaRv33/ebEVJ+0maI5N0FqEAAAa1SURBVOknkp6UtFbSPZIulPTGJvW3kDRd0p2SnpL0gqRVkr4l6f2luodKWiTpodyV6FFJt0g6p1RvG+CPSBfhDzUJcy6wNTA7Is6LiJfKFSJifURcAxzeYj8nSbpe0uM5lnsl/aOk7UpV5+VyankbBdNKdRsxrAX+AzhY0jsq1jcz6ylOGszMRoYrgefpe6E7GdiRlFS0Mo3UnWYl8DVSd59HgE8CSyVtXaq/AJgDbE66K3AJcBOwF3Bko5KkI4EbgUOAG4ALSRfU6+j7Tfx40rf7N5eDy2M1JgIvAp+r2A8AIqJPN6ycpCwGDgCuyzH/EpiZ93Gbwvq3A3cBe0g6uMm2xgAnAE8DzcY+LM3l+5ssMzPrSc1uU5uZ2WtMRDwr6evAFElvKXxbPw14hnRxe3aL1c8HTo+I9cU3JX0U+ArpAv+C/N62pATjDuCAJuuMKfxzGunLqwkR8ZNSvfJ4gUNyeXuT+BoX7ndExNMt9qElSROBWcCPgKMjYk1h2RRSovR3wF8UVpsH/Eveh6Vs7FTg9cBXIuLFJr/yx7kcT4sB3WZmvcZ3GszMRo75wGbARwAkvZXUVefyZgOLGyJidfniP/tXUsIxqVidNOh6HWn8QXlbTzTZTp8L64h4vPTWrrl8pMn6O+fy4SbLkDRD0qzSa1yhyvRcTismDDmOBaS7Ch8sbfZy0p2bk4p3IbLG3Zx5NPdoLndtsdzMrOf4ToOZ2QgREbdK+h/gI5LOJV3cjqK6a1Jj3MPHSHcQ9gS2ZeMvncYWfsczkhYBxwF3Sfp34IfArU0Sk8uBE4FbJV1Fmu1oaYsxC407FE8NaGc3NgN4a+m9G4FV+eeDgN+QEoCTmqy/BfAmSWMaSU/ez6tICdgHSV22GjM47QncFhErWsTzZC5bzr5kZtZrnDSYmY0s80n99Y8CTiN16VnezzpXAR8A7gO+RfqmfF1eNoPUFafoZOAs4BRStx6AtZKuAWZGxGMAEfFNSccCnyJdfH8MQNIdwF9FxH8Xttm4G/GGJvE1vrnfpVnwETGu8bOky+h712AM6Xx4DtW2Ij0jomF+jnsqOWmg/7sMAFvmslnXJTOznuSkwcxsZFlIGn/wJdIdgs9WVZa0Pylh+B5wVHEQcX5AWZ8nM+d+/LOAWZJ+m9R3fwrwIWAccGih7nXAdZJGkwYhHwt8HPhPSftERGNGp1/nsjgmoqExpmB/SdtExDNV+9TE08CoiNi+nZUi4hZJK4B9Je0L3AP8ManL1tcrVm3sw68r6piZ9RSPaTAzG0Fyn/1rgLeQ+uRf2c8qb8/lt5vMOvReNnxr3ur3PRgRl5PGPfwSOKQ0GLpR7/mI+H5EfBI4j9Ql6KhClUZXnz7TlEbEvaTuRlsCZ/azP83cArwxP+uhXY2uXVNJd1ZGA1dExPMV6zT24a5B/D4zs65w0mBmNvL8DenuwaSIeLafuqtyOaH4pqQdgX8uV5b0Jkl7NdnOaFL3npeBl3Ld8S0eNrdTLotjIG7M5YEt4vxz0kPbzpZ0Vh6HUY5tFFAetAzwhVzOl9Sni5Ok0ZJa/d7LSN2MTmHDNLGVY0TYsA9L+qlnZtYz3D3JzGyEiYgHgAcGWP3HpO4/J0paRnpOwk6kuwArgV+V6o8FlucB1yuAB0kX6seSZjm6pJCoXAKMlbSUlJy8BOxHepryagpdfCLip5JWAodJ2qw8m1NePgm4GpgNzJC0JO/nZvl3T8zx3Z/jaqx7g6RPk6aWvUfS9bnOVqQB1O/L+30kJRGxRtLVpGlW9yaNEbmzn8/0CNJTob/fTz0zs57hpMHMzFqKiPWSJgPnAkeTpid9mPR8hnPp+xTpVaQBxRNIF+k7kGYLWgl8mo37+p9HuuOxP+lBZ6+QLvLPAy6OiPJMSV8ELiZddH+nSazLJO1OGpx8HCn52J40M9IjpOTnWuCb5SdGR8QFOXmZTnomxPGksQ4PkwY1X1HxMc0jJQ2Nn1vK8R0IzKma5tbMrNcoIrodg5mZWb/y8xDuBZZFxPHdjmcwJF0InAHsERH3dTseM7OB8pgGMzMbFvKsSOcAkyXt1+142iXpzaSZoeY6YTCz4cbdk8zMbDj5MrAdG54CPZyMI013O6fLcZiZtc3dk8zMzMzMrJK7J5mZmZmZWSUnDWZmZmZmVslJg5mZmZmZVXLSYGZmZmZmlZw0mJmZmZlZJScNZmZmZmZWyUmDmZmZmZlVctJgZmZmZmaVnDSYmZmZmVklJw1mZmZmZlbJSYOZmZmZmVVy0mBmZmZmZpWcNJiZmZmZWaX/B5Jd3K2miZ0kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 390
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PlotWithoutModel('30epochs/30predictions.txt', '30epochs/30masspre.png', 'Mass')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
